% standard beamer lecture template for slides
% by Derek Huang
\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage{algorithm2e, amsmath, amssymb, amsfonts, graphicx}
% allow section.equation numbering
\numberwithin{equation}{section}
% use boadilla theme
\usetheme{Boadilla}
% remove navigation symbols
\usenavigationsymbolstemplate{}
% get numbered figure captions
\setbeamertemplate{caption}[numbered]
% changes itemize to circle + other things
\useoutertheme{split}
\useinnertheme{circles}

% command for the title string. change for each lecture
\newcommand{\lecturetitle}{Probabilistic generative models}
% allow automatic alert-highlighted references and hyperlinks
\newcommand{\aref}[1]{\alert{\ref{#1}}}
\newcommand{\ahref}[2]{\href{#1}{\alert{#2}}}
% title page stuff. brackets content displayed in footer bar
\title[\lecturetitle]{\lecturetitle}
% metadata. content in brackets is displayed in footer bar
\author[Derek Huang (BAC Advanced Team)]{Derek Huang}
\institute{BAC Advanced Team}
\date{March 30, 2021}

% change "ball" bullet to numbered bullet and section title for section
\setbeamertemplate{section in toc}{\inserttocsectionnumber.~\inserttocsection}
% change ball to gray square (copied from stackoverflow; \par needed for break)
\setbeamertemplate{subsection in toc}{        
    \hspace{1.2em}{\color{gray}\rule[0.3ex]{3pt}{3pt}}~\inserttocsubsection\par}
% use default enumeration scheme
\setbeamertemplate{enumerate items}[default]
% required line that fixes the problem of \mathbf, \bf not working in beamer
% for later (post-2019) TeX Live installations. see the issue on GitHub:
% https://github.com/josephwright/beamer/issues/630
\DeclareFontShape{OT1}{cmss}{b}{n}{<->ssub * cmss/bx/n}{}

\begin{document}

% title slide
\begin{frame}
    \titlepage
    \centering
    % relative path may need to be updated depending on .tex file location
    \includegraphics[scale = 0.1]{../bac_logo1.png}
\end{frame}

% table of contents slide
\begin{frame}{Overview}
    \tableofcontents
\end{frame}

% section
\section{Generative modeling}

\begin{frame}{Motivation}
    \begin{itemize}
        \item
        Let $ X : \Omega \rightarrow \mathbb{R}^d $ be the input variable,
        $ Y : \Omega \rightarrow \mathbb{R} $ be the response variable. Let
        $ \mathcal{D} \triangleq \{(\mathbf{x}_1, y_1), \ldots
        (\mathbf{x}_N, y_N)\} $ be the training data, each $ (\mathbf{x}_k,
        y_k) $ sampled independently from $ X, Y $.

        \item
        Assume a parametric model for $ X, Y $ joint or $ Y \mid X $
        conditional distribution, i.e. using a distribution parametrized by
        $ \theta \in \Theta $, $ \Theta \subseteq \mathbb{R}^p $.

        \item
        We showed that the joint likelihood $ p(\mathcal{D} \mid \theta) $
        is such that
        \begin{equation*}
            p(\mathcal{D} \mid \theta) =
            \prod_{k = 1}^Np(y_k, \mathbf{x}_k \mid \theta) \propto
            \prod_{k = 1}^Np(y_k \mid \mathbf{x}_n, \theta)
        \end{equation*}

        \item
        In linear regression, we directly modeled $ p(y \mid \mathbf{x} \mid
        \theta) $, positing $ Y \mid X \sim \mathcal{N}(\mathbf{w}^\top X + b,
        \sigma^2) $, for $ \mathbf{w} \in \mathbb{R}^d $,
        $ b \in \mathbb{R} $, $ \sigma \in (0, \infty) $.

        \item
        What's a way to model $ p(y, \mathbf{x} \mid \theta) $, the joint
        $ X, Y $ likelihood?
    \end{itemize}
\end{frame}

\subsection{Conditioning on class}

\begin{frame}{Conditioning on class}
    \begin{itemize}
        \item
        We can apply Bayes' rule to $ p(\mathcal{D} \mid \theta) $ to see that
        \begin{equation*}
            p(\mathcal{D} \mid \theta) =
            \prod_{k = 1}^Np(y_k, \mathbf{x}_k \mid \theta) =
            \prod_{k = 1}^Np(\mathbf{x}_k \mid y_k, \theta)p(y_k \mid \theta)
        \end{equation*}

        \item
        Not too helpful for regression, where usually
        $ Y(\Omega) = \mathbb{R} $, but useful for classification, where
        $ Y(\Omega) = \mathcal{C} $, $ \mathcal{C} $ some finite set of
        classes.

        \item
        $ p(\mathbf{x} \mid y, \theta) $ is a \textit{class-conditional
        likelihood}, giving the likelihood of $ \mathbf{x} $ given $ \theta $
        and knowledge that the pair $ (\mathbf{x}, y) $ belongs to class
        $ y \in \mathcal{C} $.

        \item
        $ p(y \mid \theta) $ is the \textit{class prior}, essentially
        $ \mathbb{P}\{Y = C \mid \theta\} $, $ C \in \mathcal{C} $.

        \item
        With $ p(\mathbf{x} \mid y, \theta) $ and $ p(y \mid \theta) $
        we can model $ p(\mathcal{D} \mid \theta) $ directly and even generate
        new $ (\mathbf{x}, y) $ examples, hence the moniker
        \textit{generative modeling}.
    \end{itemize}
\end{frame}

\begin{frame}{Conditioning on class}
    \begin{itemize}
        \item
        Generative modeling typically limited to classification, so from now on
        assume $ Y(\Omega) = \mathcal{C} $, $ \mathcal{C} \triangleq \{C_1,
        \ldots C_K\} $, $ K $ the number of classes.

        \item
        We usually model $ Y \mid \theta $ with the categorical distribution,
        i.e.
        \begin{equation} \label{cat_dist_like}
            p(y \mid \theta) \triangleq
            \sum_{k = 1}^Kp_k\mathbb{I}_{\{C_k\}}(y)
        \end{equation}
        Here $ K \in \mathbb{N} $, $ p_1, \ldots p_K \in (0, 1) $,
        $ \sum_{k = 1}^Kp_k = 1 $. Note $ p(C_k \mid \theta) \triangleq p_k $.

        \item        
        The \textit{class priors} $ p_1, \ldots p_K $ are typically estimated
        through maximum likelihood, i.e. $ \hat{p}_j \triangleq \frac{1}{N}
        \sum_{k = 1}^N\mathbb{I}_{\{C_j\}}(y_k) $ is the estimate for $ p_j $.

        \item
        The major difference between generative models is how to model
        $ p(\mathbf{x} \mid y, \theta) $, which depends on assumptions and on
        the type of input.
    \end{itemize}
\end{frame}

\subsection{Bernoulli naive Bayes}

\begin{frame}{Bernoulli naive Bayes}
    \begin{itemize}
        \item
        Suppose $ X(\Omega) = \{0, 1\}^d $, where for $ i \in
        \{1, \ldots d\} $, $ j \in \{1, \ldots K\} $,
        $ X_i \mid Y \sim \operatorname{Bernoulli}(p_{Y, i}) $,
         $ X_1 \mid Y, \ldots X_d \mid Y $ mutually independent\footnote{
            Class-conditional input feature independence is the
            \textit{naive Bayes} assumption \cite{bishop_ml}.
        }, $ p_{C_1, 1}, \ldots p_{C_K, d} \in (0, 1) $. Writing the class
        explicitly, we have
        \begin{equation} \label{bern_nb_like}
            p(\mathbf{x} \mid C_j, \theta) =
            \prod_{i = 1}^dp(x_i \mid C_j, \theta) \triangleq
            \prod_{i = 1}^dp_{C_j, i}^{x_i}(1 - p_{C_j, i})^{1 - x_i}
        \end{equation}

        \item
        Again, the $ p_{C_j, i} $ parameters are typically estimated by
        maximum likelihood, i.e. the estimate $ \hat{p}_{C_j, i} $ is such that
        \begin{equation} \label{bern_nb_param_mle}
            \hat{p}_{C_j, i} \triangleq \frac{N_{C_j, i}}{N_{C_j}} \triangleq
            \frac{
                |\{(\mathbf{x}, y) \in \mathcal{D} : x_i = 1, y = C_j\}|
            }{
                |\{(\mathbf{x}, y) \in \mathcal{D} : y = C_j\}|
            } 
        \end{equation}
    \end{itemize}
\end{frame}

\subsection{Gaussian naive Bayes}

\begin{frame}{Gaussian naive Bayes}
    \begin{itemize}
        \item
        Suppose $ X(\Omega) = \mathbb{R}^d $, where for
        $ i \in \{1, \ldots d\} $, $ j \in \{1, \ldots K\} $,
        $ X_i \mid Y \sim \mathcal{N}(\mu_{Y, i}, \sigma_{Y, i}^2) $,
        $ X_1 \mid Y, \ldots X_d \mid Y $ mutually independent,
        $ \mu_{C_1, 1}, \ldots \mu_{C_K, d} \in \mathbb{R} $,
        $ \sigma_{C_1, 1}, \ldots \sigma_{C_K, d} \in (0, \infty) $. Then,
        \begin{equation} \label{normal_nb_like}
            p(\mathbf{x} \mid C_j, \hat{\theta}) \triangleq
            \prod_{i = 1}^d\frac{1}{\sqrt{2\pi}\sigma_{C_j, i}}e^{
                -\frac{1}{2}\sigma_{C_j, i}^{-2}(x_i - \mu_{C_j, i})^2
            }
        \end{equation}

        \item
        Maximum likelihood estimates for $ \mu_{C_j, i}, \sigma_{C_j, i}^2 $
        are
        \begin{equation} \label{normal_nb_param_mle}
            \begin{split}
            \hat{\mu}_{C_j, i} & \triangleq \frac{1}{|\mathcal{D}_{C_j}|}
                \sum_{(\mathbf{x}, y) \in \mathcal{D}_{C_j}}x_i \\
            \sigma_{C_j, i}^2 & \triangleq \frac{1}{|\mathcal{D}_{C_j}|}
                \sum_{(\mathbf{x}, y) \in \mathcal{D}_{C_j}}
                (x_i - \hat{\mu}_{C_j, i})^2
            \end{split}
        \end{equation}
        Here $ \mathcal{D}_{C_j} \triangleq \{(\mathbf{x}, y) \in
        \mathcal{D} : y = C_j\} $, the set of class $ C_j $ examples.
    \end{itemize}
\end{frame}

\section{Discriminant analysis}

\subsection{Linear discriminant analysis}

\begin{frame}{Linear discriminant analysis}
    \begin{itemize}
        \item
        Dropping the naive Bayes assumption, let
        $ X \mid Y \sim \mathcal{N}(\mu_Y, \mathbf{\Sigma}) $, $ \mu_{C_1},
        \ldots \mu_{C_K} \in \mathbb{R}^d $, $ \mathbf{\Sigma} \succ \mathbf{0}
        \in \mathbb{R}^{d \times d} $.
        Then, $ \forall j \in \{1, \ldots K\} $,
        \begin{equation} \label{lda_like}
            p(\mathbf{x} \mid C_j, \hat{\theta}) \triangleq \frac{1}{
                (2\pi)^d|\mathbf{\Sigma}|^{1 / 2}
            }e^{
                -\frac{1}{2}(\mathbf{x} - \mu_{C_j})^\top
                \mathbf{\Sigma}^{-1}(\mathbf{x} - \mu_{C_j})
            }
        \end{equation}

        \item
        Maximum likelihood estimates for $ \mu_{C_1}, \ldots \mu_{C_K},
        \mathbf{\Sigma} $ are
        \begin{equation}
            \begin{split}
            \hat{\mu}_{C_j} & \triangleq \frac{1}{|\mathcal{D}_{C_j}|}
                \sum_{(\mathbf{x}, y) \in \mathcal{D}_{C_j}}\mathbf{x} \\
            \hat{\mathbf{\Sigma}} & \triangleq
                \frac{1}{N}
                \sum_{k = 1}^N
                (\mathbf{x}_k - \hat{\mu}_{y_k})
                (\mathbf{x}_k - \hat{\mu}_{y_k})^\top
            \end{split}
        \end{equation}

        \item
        Note the shared covariance matrix $ \hat{\mathbf{\Sigma}} $ and that
        $ \hat{\mu}_{y_k} = \hat{\mu}_{C_j} $ if $ y_k = C_j $.
    \end{itemize}
\end{frame}

\subsection{Quadratic discriminant analysis}

\begin{frame}{Quadratic discriminant analysis}
    \begin{itemize}
        \item
        Suppose we let $ X \mid Y \sim \mathcal{N}(\mu_Y, \mathbf{\Sigma}_Y) $,
        $ \mu_{C_1}, \ldots \mu_{C_K} \in \mathbb{R}^d $,
        $ \mathbf{\Sigma}_{C_1}, \ldots \mathbf{\Sigma}_{C_K} \succ \mathbf{0}
        \in \mathbb{R}^{d \times d} $. Then, $ \forall j \in \{1, \ldots K\} $,
        \begin{equation} \label{qda_like}
            p(\mathbf{x} \mid C_j, \hat{\theta}) \triangleq \frac{1}{
                (2\pi)^d|\mathbf{\Sigma}_{C_j}|^{1 / 2}
            }e^{
                -\frac{1}{2}(\mathbf{x} - \mu_{C_j})^\top
                \mathbf{\Sigma}_{C_j}^{-1}(\mathbf{x} - \mu_{C_j})
            }
        \end{equation}

        \item
        Maximum likelihood estimates for $ \mu_{C_1}, \ldots \mu_{C_K},
        \mathbf{\Sigma}_{C_1}, \ldots \mathbf{\Sigma}_{C_K} $ are
        \begin{equation}
            \begin{split}
            \hat{\mu}_{C_j} & \triangleq \frac{1}{|\mathcal{D}_{C_j}|}
                \sum_{(\mathbf{x}, y) \in \mathcal{D}_{C_j}}\mathbf{x} \\
            \hat{\mathbf{\Sigma}}_{C_j} & \triangleq
                \frac{1}{|\mathcal{D}_{C_j}|}
                \sum_{(\mathbf{x}, y) \in \mathcal{D}_{C_j}}
                (\mathbf{x} - \hat{\mu}_{C_j})
                (\mathbf{x} - \hat{\mu}_{C_j})^\top
            \end{split}
        \end{equation}

        \item
        Note each class $ C_j $ has its own covariance matrix
        $ \mathbf{\Sigma}_{C_j} $.
    \end{itemize}
\end{frame}

\subsection{Decision boundaries}

\begin{frame}{Decision boundaries}
    \begin{itemize}
        \item
        Origin of linear and quadratic as discriminant analysis
        differentiators?

        \item
        For any fitted probabilistic classifier with estimated parameters
        $ \hat{\theta} $, given an unlabeled point $ \mathbf{x} \in
        \mathbb{R}^d $, the natural classification rule is
        \begin{equation} \label{class_rule}
            \arg\max_{C_j \in \mathcal{C}}p(C_j \mid \mathbf{x}, \hat{\theta})
        \end{equation}

        \item
        Note that for class $ C_j $, $ j \in \{1, \ldots K\} $, we have
        \begin{equation}
            p(C_j \mid \mathbf{x}, \hat{\theta}) =
            \frac{p(C_j, \mathbf{x} \mid \hat{\theta})}{
                p(\mathbf{x} \mid \hat{\theta})
            } = \frac{
                p(\mathbf{x} \mid C_j, \hat{\theta})p(C_j \mid \hat{\theta})
            }{
                \sum_{j = 1}^Kp(\mathbf{x} \mid C_j, \hat{\theta})
                p(C_j \mid \hat{\theta})
            }
        \end{equation}
        We use definition of conditional probability, Bayes' rule, and law of
        total probability since $ \mathcal{D}_{C_1} \cap \ldots
        \mathcal{D}_{C_K} = \emptyset $. Note
        $ p(\mathbf{x} \mid \hat{\theta}) = p(\mathbf{x}) $.

        \item
        For compactness of notation, let
        $ p_{C_j \mid \hat{\theta}} \triangleq p(C_j \mid \hat{\theta}) $.
    \end{itemize}
\end{frame}

\begin{frame}{Decision boundaries}
    \begin{itemize}
        \item
        $ p(\mathbf{x}) $ doesn't change with $ C_j $. Given a fitted
        generative model with parameters $ \hat{\theta} $, we can rewrite
        (\aref{class_rule}) as\footnote{
            $ \arg\max $ invariant to positive scaling and monotone
            increasing transformations \cite{bv_convex_opt}.
        }
        \begin{equation*}
            \arg\max_{C_j \in \mathcal{C}}\left\{
                \log p(\mathbf{x} \mid C_j, \hat{\theta}) +
                \log p_{C_j \mid \hat{\theta}}
            \right\}
        \end{equation*}

        \item
        Let $ p(\mathbf{x} \mid C_j, \hat{\theta}) $ be as defined in
        (\aref{qda_like}). Take two classes $ C_a, C_b \in \mathcal{C} $ and
        note the \textit{decision boundary} $ \mathcal{B}_{C_a, C_b} $ between
        them is
        \begin{equation} \label{decision_boundary}
            \begin{split}
            \mathcal{B}_{C_a, C_b} & \triangleq \{\mathbf{x} \in \mathbb{R}^d :
                p(C_a \mid \mathbf{x}, \hat{\theta}) =
                p(C_b \mid \mathbf{x}, \hat{\theta})\} \\ & =
                \left\{
                    \mathbf{x} \in \mathbb{R}^d : \log\frac{
                        p(\mathbf{x} \mid C_a, \hat{\theta})
                    }{p(\mathbf{x} \mid C_b, \hat{\theta})} + \log\frac{
                        p_{C_a \mid \hat{\theta}}
                    }{p_{C_b \mid \hat{\theta}}} = 0
                \right\}
            \end{split}
        \end{equation}
        We use properties of logarithms and the fact that the
        $ p(\mathbf{x} \mid \hat{\theta}) $ terms in the denominator of
        $ p(C_a \mid \mathbf{x}, \hat{\theta}), p(C_b \mid \mathbf{x},
        \hat{\theta}) $ cancel to see this.
    \end{itemize}

    % spacing for footnote
    \medskip
\end{frame}

\begin{frame}{Decision boundaries}
    \begin{itemize}
        \item
        After some tedious math, under QDA (\aref{decision_boundary}) becomes
        \begin{equation} \label{qda_decision_boundary}
            \mathcal{B}_{C_a, C_b} = \left\{
                \mathbf{x} \in \mathbb{R}^d : \frac{1}{2}
                \mathbf{x}^\top\hat{\mathbf{Q}}_{C_a, C_b}\mathbf{x} -
                \hat{\mathbf{a}}_{C_a, C_b}^\top\mathbf{x} +
                \hat{b}_{C_a, C_b} = 0
            \right\}
        \end{equation}
        Here $ \hat{\mathbf{Q}}_{C_a, C_b} \in \mathbb{R}^{d \times d},
        \hat{\mathbf{a}}_{C_a, C_b} \in \mathbf{R}^d, \hat{b}_{C_a, C_b} \in
        \mathbb{R} $ are such that
        \begin{equation*}% \label{qda_decision_constants}
            \begin{split}
            \hat{\mathbf{Q}}_{C_a, C_b} & \triangleq
                \hat{\mathbf{\Sigma}}_{C_a}^{-1} -
                \hat{\mathbf{\Sigma}}_{C_b}^{-1} \\
            \hat{\mathbf{a}}_{C_a, C_b} & \triangleq
                \hat{\mathbf{\Sigma}}_{C_a}^{-1}\hat{\mu}_{C_a} -
                \hat{\mathbf{\Sigma}}_{C_b}^{-1}\hat{\mu}_{C_b} \\
            \hat{b}_{C_a, C_b} & \triangleq
                \frac{1}{2}\left(
                    \hat{\mu}_{C_a}^\top
                    \hat{\mathbf{\Sigma}}_{C_a}^{-1}\hat{\mu}_{C_a} -
                    \hat{\mu}_b^\top
                    \hat{\mathbf{\Sigma}}_{C_b}^{-1}\hat{\mu}_{C_b} +
                    \log\frac{
                        |\hat{\mathbf{\Sigma}}_{C_a}|
                    }{|\hat{\mathbf{\Sigma}}_{C_b}|}
                \right) - \log\frac{p_{C_a \mid \hat{\theta}}}{
                    p_{C_b \mid \hat{\theta}}
                }
            \end{split}
        \end{equation*}

        % remove some excess space
        \vspace{-5 pt}

        \item
        $ \mathcal{B}_{C_a, C_b} $ under QDA is the solution set of a
        quadratic equation\footnote{
            $ \mathcal{B}_{C_a, C_b} $ is also apparently known as a
            \textit{quadric hypersurface}.        
        }.
    \end{itemize}

    % correct spacing for footnote
    \medskip
\end{frame}

\begin{frame}{Decision boundaries}
    \begin{itemize}
        \item
        If we let $ p(\mathbf{x} \mid C_j, \hat{\theta}) $ be defined as in
        (\aref{lda_like}), then $ \hat{\mathbf{\Sigma}}_{C_a} =
        \hat{\mathbf{\Sigma}}_{C_b} = \hat{\mathbf{\Sigma}} $, so
        \begin{equation} \label{lda_decision_boundary}
            \mathcal{B}_{C_a, C_b} = \big\{
                \mathbf{x} \in \mathbb{R}^d :
                    \hat{\mathbf{a}}_{C_a, C_b}^\top\mathbf{x} =
                    \hat{b}_{C_a, C_b}
            \big\}
        \end{equation}
        Note $ \hat{\mathbf{Q}}_{C_a, C_b} $ simplifies to $ \mathbf{0} $ and
        that $ \hat{\mathbf{a}}_{C_a, C_b}, \hat{b}_{C_a, C_b} $ are such that
        \begin{equation*}
            \begin{split}
            \hat{\mathbf{a}}_{C_a, C_b} & = \hat{\mathbf{\Sigma}}
                \big(\hat{\mu}_{C_a} - \hat{\mu}_{C_b}\big) \\
            \hat{b}_{C_a, C_b} & = \frac{1}{2}
                \big(\hat{\mu}_{C_a} + \hat{\mu}_{C_b}\big)^\top
                \hat{\mathbf{\Sigma}}
                \big(\hat{\mu}_{C_a} - \hat{\mu}_{C_b}\big)
            - \log\frac{
                p_{C_a \mid \hat{\theta}}
            }{p_{C_b \mid \hat{\theta}}}
            \end{split}
        \end{equation*}

        \item
        $ \mathcal{B}_{C_a, C_b} $ under LDA is the solution set of a linear
        equation (hyperplane).

        \item
        Assuming the $ K $ classes share the same covariance matrix
        $ \hat{\mathbf{\Sigma}} $ leads to \alert{linear} decision boundaries
        while assuming different covariance matrices
        $ \hat{\mathbf{\Sigma}}_{C_1}, \ldots \hat{\mathbf{\Sigma}}_{C_K} $
        per class leads to \alert{quadratic} decision boundaries.
    \end{itemize}
\end{frame}

%\section{Smoothing and shrinkage}
%
%\subsection{Probability smoothing}
%
%\begin{frame}{Probability smoothing}
%    \begin{itemize}
%        \item
%        Recall the Bernoulli naive Bayes model whose likelihood was defined
%        in (\ref{bern_nb_like}).
%    \end{itemize}
%\end{frame}
%
%\subsection{Covariance matrix shrinkage}

% BibTeX slide for references. should use either acm or ieeetr style
\begin{frame}{References}
    \bibliographystyle{acm}
    % relative path may need to be updated depending on .tex file location
    \bibliography{../master_bib}
\end{frame}

\end{document}